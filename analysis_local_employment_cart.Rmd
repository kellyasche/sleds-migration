---
title: "Analysis - local employment CART"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
runtime: shiny
resource_files:
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.cpg
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.dbf
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.prj
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.sbn
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.sbx
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.shp.xml
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.shx
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(sf)
library(ggrepel)
library(scales)
library(shiny)
library(shinycssloaders)
library(ggiraph)
library(kableExtra)
library(rmapshaper)
library(cowplot)
library(DT)
library(htmlwidgets)
library(RColorBrewer)
library(readxl)
library(janitor)
library(lubridate)
library(systemfonts)
reset_font_cache()
library(ggtext)
library(gmodels)
library(fastDummies)
library(car)
library(glmnet)
library(glmnetUtils)
library(pscl)
library(sjPlot)
library(rpart)
library(rpart.plot)
```

```{r join docs, include=FALSE}
theme_bar <- theme_bw() +
  theme(panel.grid.major = element_line(color = "grey70", size = 0.1),
        panel.grid.minor = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(face = "bold"),
        panel.border = element_blank(),
        legend.background = element_rect(fill = "transparent", color = "transparent"),
        legend.key = element_rect(fill = "transparent"),
        legend.key.size = unit(1, "lines"),
        legend.margin = margin(0,0,0,0),
        legend.title = element_blank(),
        legend.text = element_text(margin = margin(l = 2)),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))

theme_line <- theme_bw() +
  theme(legend.background = element_rect(fill = "transparent", color = "transparent"),
        legend.key = element_rect(fill = "transparent"),
        legend.text = element_text(margin = margin(l = 2)),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_line(color = "grey70", size = 0.1),
        axis.ticks = element_blank(),
        axis.text = element_text(face = "bold"),
        panel.border = element_blank(),
        legend.margin = margin(0,0,0,0),
        legend.key.size = unit(1, "lines"),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))


theme_sf <- theme_bw() +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks=element_blank(),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "white"),
        panel.border = element_blank(),
        legend.title = element_blank(),
        legend.text = element_text(margin = margin(l = 2)),
        legend.margin = margin(0,0,0,0),
        legend.key.size = unit(1, "lines"),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))

regions <- read_csv("Data/Join docs/county_regions.csv") %>%
    select(5,6) %>%
    unique() %>%
    mutate(edr = str_replace(edr, "  ", " "),
           planning.region = str_replace(planning.region, " Minnesota", ""),
           planning.region = fct_relevel(planning.region, "Northwest", "Northeast", "Central", "Seven County Mpls-St Paul", "Southwest", "Southeast"),
           edr = fct_relevel(edr, "EDR 1 - Northwest", "EDR 2 - Headwaters", "EDR 3 - Arrowhead", "EDR 4 - West Central", "EDR 5 - North Central", "EDR 6E- Southwest Central", "EDR 6W- Upper Minnesota Valley", "EDR 7E- East Central", "EDR 7W- Central", "EDR 8 - Southwest", "EDR 9 - South Central", "EDR 10 - Southeast", "EDR 11 - 7 County Twin Cities", "Minnesota"))

counties.regions <- read_csv("Data/Join docs/county_regions.csv") %>%
  rename(mif = `MIF Region`) %>%
  mutate(countyfp = formatC(countyfp, width = 3, flag = "0"),
         Name = str_to_title(Name),
         Name = str_replace(Name, "Q", "q"),
         Name = str_replace(Name, "Of The", "of the"),
         Name = str_replace(Name, "Mcleod", "McLeod"),
         Dem_Desc = ifelse(Name == "Minnesota", "Minnesota", Dem_Desc) ,
         edr = str_replace(edr, "  ", " "),
         planning.region = str_replace(planning.region, " Minnesota", ""),
         planning.region = fct_relevel(planning.region, "Northwest", "Northeast", "Central", "Seven County Mpls-St Paul", "Southwest", "Southeast"),
         edr = fct_relevel(edr, "EDR 1 - Northwest", "EDR 2 - Headwaters", "EDR 3 - Arrowhead", "EDR 4 - West Central", "EDR 5 - North Central", "EDR 6E- Southwest Central", "EDR 6W- Upper Minnesota Valley", "EDR 7E- East Central", "EDR 7W- Central", "EDR 8 - Southwest", "EDR 9 - South Central", "EDR 10 - Southeast", "EDR 11 - 7 County Twin Cities", "Minnesota"),
         mif = ifelse(is.na(mif), "TC", mif),
         mif = as.factor(mif),
         mif = fct_relevel(mif, "NW", "NE", "WC", "EC", "SW", "SE", "TC"))


color.ruca <- c("Entirely rural" = "#009933", "Town/rural mix" = "#99CC33", "Urban/town/rural mix" = "#CC9966", "Entirely urban" = "#754C29", "Minnesota" = "black")

color.pr <- c("Northwest" = 	"#4575b4", "Northeast" = "grey", "Central" = "#fee090", "Seven County Mpls-St Paul" = "#d73027", "Southwest" = "#91bfdb", "Southeast" = "#fc8d59", "Minnesota" = "black")

color.edr <- c("EDR 1 - Northwest" = "#b3cde3", "EDR 2 - Headwaters" = "#8c96c6", "EDR 3 - Arrowhead" = "#fe9929", "EDR 4 - West Central" = "#8856a7", "EDR 5 - North Central" = "#810f7c", "EDR 6E- Southwest Central" = "#e5f5f9", "EDR 6W- Upper Minnesota Valley" = "#bdc9e1", "EDR 7E- East Central" = "#99d8c9", "EDR 7W- Central" = "#2ca25f", "EDR 8 - Southwest" = "#74a9cf", "EDR 9 - South Central" = "#0570b0", "EDR 10 - Southeast" = "#d7301f", "EDR 11 - 7 County Twin Cities" = "#d8b365", "Minnesota" = "black")

color.pr.edr <- c ("Northwest" = "#4575b4","Northeast" = "#e0f3f8", "Central" = "#fee090", "Seven County Mpls-St Paul" = "#d73027", "Southwest" = "#91bfdb", "Southeast" = "#fc8d59", "Minnesota" = "black", "EDR 1 - Northwest" = "#b3cde3", "EDR 2 - Headwaters" = "#8c96c6", "EDR 3 - Arrowhead" = "#fe9929", "EDR 4 - West Central" = "#8856a7", "EDR 5 - North Central" = "#810f7c", "EDR 6E- Southwest Central" = "#e5f5f9", "EDR 6W- Upper Minnesota Valley" = "#bdc9e1", "EDR 7E- East Central" = "#99d8c9", "EDR 7W- Central" = "#2ca25f", "EDR 8 - Southwest" = "#74a9cf", "EDR 9 - South Central" = "#0570b0", "EDR 10 - Southeast" = "#d7301f", "EDR 11 - 7 County Twin Cities" = "#d8b365")

mn_counties <- st_read("Data/Shapefiles/county shapefiles/MNCounties_MNDOT.shp", quiet = TRUE) %>%
  ms_simplify(keep = .01, keep_shapes = TRUE) %>%
  rename(countyfp = FIPS_CODE)


```

```{r master dataset}
master.after.ct <- read_csv("Data/SLEDS/Masters/Master-after-ct.csv") %>%
    mutate_at(c(2:16, 18:23, 25, 29:33), as.factor) 

```


<br>

We will use a tree-based method for classification - CART analysis. This type of analysis involves stratifying and/or segmenting the predictor space into a number of simple regions. Essentially, it's another way to see which independent variables play a role in if an individual has meaningful employment in the local region X. We will be using the independent variables that were identified as being important in the multiple correspondence analysis.

There are three "times" in which we checked to see if the individual had meaningful employment within these geographies;

1. the same year as graduation
2. two years after graduation, and
3. seven years after graduation. 

Meaningful employment is determined by whether an individual worked 1,000 hours for an employer during time X. In addition, if the individual worked 1,000 hours for that employer during another year, but not for that exact "time X" year, it's still considered "meaningful". 

Due to time x potentially being passed the date of the latest data (2019) for some individuals, the analysis below will filter out all individuals where time x is after 2019. 

The primary independent variables that the cross tables indicated as important are;

```{r list of ind var}
ind.var <- master.after.ct %>%
  select(-PersonID, -hs.grad.year.county.match, -hs.grad.year.2.county.match, -hs.grad.year.7.county.match, -hs.grad.year.edr.match, -hs.grad.year.2.edr.match, -hs.grad.year.7.edr.match, -hs.grad.year.region.match, -hs.grad.year.region.match, -hs.grad.year.2.region.match, -hs.grad.year.7.region.match, -hs.grad.year.state.match, -hs.grad.year.2.state.match, -hs.grad.year.7.state.match) 

dep.var.names <- master.after.ct %>%
  select(hs.grad.year.county.match, hs.grad.year.2.county.match, hs.grad.year.7.county.match, hs.grad.year.edr.match, hs.grad.year.2.edr.match, hs.grad.year.7.edr.match, hs.grad.year.region.match, hs.grad.year.region.match, hs.grad.year.2.region.match, hs.grad.year.7.region.match, hs.grad.year.state.match, hs.grad.year.2.state.match, hs.grad.year.7.state.match) %>%
  names()

ind.var.names <- ind.var %>%
  names()

ind.var %>%
  lapply(class)
```
However, there are plenty of variables here that are VERY similar. For example, whether an individual graduated from a post-secondary institution and the type of institution they graduated from. So let's simplify the variables to what is most important and has the least amount of overlap with other variables.

* Demographic
    + RaceEthnicity
* High school characteristics
    + Dem_Desc
    + EDR
    + avg.wages.pct.state
* High school enrollment
    + LimitedEnglishProficiencyIndicator
    + PSEO.participant
* High school accomplishments
    + took.act
    + ap.exam
    + cte.achievement
    + MCA.M
    + MCA.R
    + MCA.S
* Post-secondary
    + attended.ps.within.first.year.hsgrad: only for grad year +0 dependent variable
    + ps.grad.InstitutionSector
    + highest.cred.level
    
We eliminated the following variables for now;

* non.english.home
* english.learner
* total.cte.courses.taken
* ps.grad
* attended.ps

In addition to eliminating those variables, we will also simplify the ps.grad.InstitutionSector to the following codes;

* 1 = graduated from the following insitutions
    + Public, 4-year (1)
    + Private, not for profit 4-year (2)
    + Private, for profit 4-year (3)
* 2 = graduated from the following institutions
    + Private, not for profit 2-year (5, 11)
    + Private, for profit 2-year (6, 11)
    + Public, less than 2-year (7, 11)
    + Private, not for profit less than 2-year (8, 11)
    + Private for-profit, less-than 2-year (9, 11)
* 3 = graduated from multiple institution sectors (10)
* 4 = graduated from a public, 2-year institution (4,4)
* 5 = Did not graduate or attend a post-secondary institution

We will also simplify the attended.ps.within.first.year.hsgrad variable to the following;

* Yes = Attended PS within first year
* No = Attended PS but not within first year & never attended PS

```{r updating master}
updated.master <- master.after.ct %>%
  select(`dep.var.names`, RaceEthnicity, Dem_Desc, edr, avg.wages.pct.state, LimitedEnglishProficiencyIndicator, pseo.participant, took.ACT, ap.exam, cte.achievement, MCA.M, MCA.R, MCA.S, attended.ps.within.first.year.hsgrad, ps.grad.InstitutionSector, highest.cred.level) %>%
  mutate(ps.grad.InstitutionSector = ifelse(ps.grad.InstitutionSector %in% c(1,2,3), 1,
                                            ifelse(ps.grad.InstitutionSector == 11, 2,
                                                   ifelse(ps.grad.InstitutionSector == 10, 3,
                                                          ifelse(ps.grad.InstitutionSector == 4, 4, 5)))),
         attended.ps.within.first.year.hsgrad = ifelse(attended.ps.within.first.year.hsgrad == "Attended first year after HS", "Yes", "No")) 

updated.ind.var.names <- updated.master %>%
  select(-`dep.var.names`) %>%
  names()

```

<br>

# Steps in analysis

Our dependent variable - the individual has meaningful employment in same location X as their high school - has 4 different outcomes.

1. Location match: the individual has
    + a MN employment record at time X
    + has meaningful employment at time X
    + is employed in the same location X as their high school.
2. No location match: the individual has 
    + a MN employment record at time X
    + has meaningful employment at time X
    + does NOT have employment in the same location X as their high school.
3. No meaningful emp: the individual has
    + a MN employment record at time X
    + the employment is not meaningful at time X.
4. No MN emp record: the individual has
    + NO MN employment record at time X.
    
Since we are most interested in whether an individual has meaningful employment in region X at time X we will create two groups; 1. all individuals that meet the criteria/outcome 1 from list above, and 2. all remaining individuals.
    
For each time X we will analyze whether the independent variables are good at predicting whether an individual has a MN employment record AND has meaningful employment AND the meaningful employment is in the same region X as their high school.



<br>

# Analysis - time X = grad year +0

## County meaningful employment

```{r master CART grad year county}
master.grad.year.county.path <- updated.master %>%
  select(hs.grad.year.county.match, `updated.ind.var.names`, -highest.cred.level)  %>%
  filter(hs.grad.year.county.match != "Unknown") %>%
  filter(hs.grad.year.county.match != "After 2019") %>%
  drop_na(hs.grad.year.county.match) %>%
  mutate(hs.grad.year.county.match = ifelse(hs.grad.year.county.match == "Location match", "Match", "No match")) 


```
The following analysis will determine which variables are most important in predicting whether an individual has meaningful employment in the same county as their high school the year they graduate.

Let's split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train grad year +0 county, echo=TRUE}
set.seed(1234)
sample_ind <- sample(nrow(master.grad.year.county.path), nrow(master.grad.year.county.path) *.7)

train <- master.grad.year.county.path[sample_ind,]

test <- master.grad.year.county.path[-sample_ind,]
```

<br>

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

<br>

```{r create decision tree grad year +0 county, echo=TRUE}
#Base model
grad.year.0.county.model <- rpart(hs.grad.year.county.match ~ ., data = master.grad.year.county.path)

```

```{r decision tree summary and plots grad year +0 county, echo=TRUE, include=FALSE}

#Summary
summary(grad.year.0.county.model)

#Plot tree
rpart.plot(grad.year.0.county.model)

```

```{r decision tree error grad year +0 county, echo=TRUE}

# Examine the complexity plot
printcp(grad.year.0.county.model)
plotcp(grad.year.0.county.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable important and it shows that average wages, post-secondary pathway, MCA-reading scores, EDR, and CTE achievement play an important role in this model.

<br>

```{r base model variable importance grad year +0 county, echo=TRUE}
grad.year.0.county.model$variable.importance
```

<br>

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy grad year +0 county, echo=TRUE}
test$pred <- predict(grad.year.0.county.model, test, type = "class")

base_accuracy <- mean(test$pred == test$hs.grad.year.county.match)

base_accuracy
```

<br>

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket.

<br>

```{r pre pruning  grad year +0 county, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
grad.year.0.county.model.preprune <- rpart(hs.grad.year.county.match ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 10, minsplit = 40))

#Summary
summary(grad.year.0.county.model.preprune)

#Plot tree
rpart.plot(grad.year.0.county.model.preprune)

# Examine the complexity plot
printcp(grad.year.0.county.model.preprune)
plotcp(grad.year.0.county.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(grad.year.0.county.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$hs.grad.year.county.match)

accuracy_preprun
```

<br>

The pre-pruning resulted in a significantly less complex tree with a .877442 accuracy. Let's see what variables are important in this model.

This model does indicate a difference in important when pruned. Average wages are no longer as important, however post-secondary pathway is still very important. 

<br>

```{r pre pruning variable importance grad year +0 county, echo=TRUE}
grad.year.0.county.model.preprune$variable.importance

```

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code:

<br>

```{r postpruning grad year +0 county, echo=TRUE}

# Prune the hr_base_model based on the optimal cp value
grad.year.0.county.model.postprune <- prune(grad.year.0.county.model, cp = .00024657 )

#Summary
summary(grad.year.0.county.model.postprune)

#Plot tree
rpart.plot(grad.year.0.county.model.postprune)

# Examine the complexity plot
printcp(grad.year.0.county.model.postprune)
plotcp(grad.year.0.county.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(grad.year.0.county.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$hs.grad.year.county.match)

accuracy_postprun

```

<br>

We still end up with a highly complex tree that is difficult to interpret. Let's check to see what variables are considered important.

And it tells me that none of the variables are important?????

<br>

```{r post pruning variable importance grad year +0 county, echo=TRUE}
grad.year.0.county.model.postprune$variable.importance

```
<br>

Now let's compare the accuracy.

```{r compare accuracy grad year +0 county, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

<br>

# Analysis - time X = grad year +2

## County meaningful employment

```{r master CART grad year +2 county}
master.grad.year.2.county.path <- updated.master %>%
  select(hs.grad.year.2.county.match, `updated.ind.var.names`, -highest.cred.level)  %>%
  filter(hs.grad.year.2.county.match != "Unknown") %>%
  filter(hs.grad.year.2.county.match != "After 2019") %>%
  drop_na(hs.grad.year.2.county.match) %>%
  mutate(hs.grad.year.2.county.match = ifelse(hs.grad.year.2.county.match == "Location match", "Match", "No match")) 


```
The following analysis will determine which variables are most important in predicting whether an individual has meaningful employment in the same county as their high school the year they graduate.

Let's split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train grad year +2 county, echo=TRUE}
set.seed(1234)
sample_ind <- sample(nrow(master.grad.year.2.county.path), nrow(master.grad.year.2.county.path) *.7)

train <- master.grad.year.2.county.path[sample_ind,]

test <- master.grad.year.2.county.path[-sample_ind,]
```

<br>

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

<br>

```{r create decision tree grad year +2 county, echo=TRUE}
#Base model
grad.year.2.county.model <- rpart(hs.grad.year.2.county.match ~ ., data = train, method = "class", control = rpart.control(cp = 0))

```

```{r decision tree summary and plots grad year +2 county, echo=TRUE, include=FALSE}

#Summary
summary(grad.year.2.county.model)

#Plot tree
rpart.plot(grad.year.2.county.model)

```

```{r decision tree error grad year +2 county, echo=TRUE}

# Examine the complexity plot
printcp(grad.year.2.county.model)
plotcp(grad.year.2.county.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable important and it shows that ps.grad.InstitutionSector,  average wages, cte.achievement, ap.exam and edr play an important role in this model.

<br>

```{r base model variable importance grad year +2 county, echo=TRUE}
grad.year.2.county.model$variable.importance
```

<br>

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy grad year +2 county, echo=TRUE}
test$pred <- predict(grad.year.2.county.model, test, type = "class")

base_accuracy <- mean(test$pred == test$hs.grad.year.2.county.match)

base_accuracy
```

<br>

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket.

<br>

```{r pre pruning  grad year +2 county, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
grad.year.2.county.model.preprune <- rpart(hs.grad.year.2.county.match ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 6, minsplit = 40))

#Summary
summary(grad.year.2.county.model.preprune)

#Plot tree
rpart.plot(grad.year.2.county.model.preprune)

# Examine the complexity plot
printcp(grad.year.2.county.model.preprune)
plotcp(grad.year.2.county.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(grad.year.2.county.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$hs.grad.year.2.county.match)

accuracy_preprun
```

<br>

The pre-pruning resulted in a significantly less complex tree with a .8260277 accuracy. Let's see what variables are important in this model.

Variable importance doesn't change much from the initial model. Post-secondary pathway, cte achievement, average wages and ap.exam are still the top.

<br>

```{r pre pruning variable importance grad year +2 county, echo=TRUE}
grad.year.2.county.model.preprune$variable.importance

```

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code:

<br>

```{r postpruning grad year +2 county, echo=TRUE}

# Prune the hr_base_model based on the optimal cp value
grad.year.2.county.model.postprune <- prune(grad.year.2.county.model, cp = .00051533 )

#Summary
summary(grad.year.2.county.model.postprune)

#Plot tree
rpart.plot(grad.year.2.county.model.postprune)

# Examine the complexity plot
printcp(grad.year.2.county.model.postprune)
plotcp(grad.year.2.county.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(grad.year.2.county.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$hs.grad.year.2.county.match)

accuracy_postprun

```

<br>

We still end up with a highly complex tree that is difficult to interpret. Let's check to see what variables are considered important.

It shows a bit of difference. The post-secondary pathway is still the top followed by average wages, however EDR jumps up above AP exam.

<br>

```{r post pruning variable importance grad year +2 county, echo=TRUE}
grad.year.2.county.model.postprune$variable.importance

```
<br>

Now let's compare the accuracy.

```{r compare accuracy grad year +2 county, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

<br>

# Analysis - time X = grad year +7

## County meaningful employment

```{r master CART grad year +7 county}
master.grad.year.7.county.path <- updated.master %>%
  select(hs.grad.year.7.county.match, `updated.ind.var.names`, -highest.cred.level)  %>%
  filter(hs.grad.year.7.county.match != "Unknown") %>%
  filter(hs.grad.year.7.county.match != "After 2019") %>%
  drop_na(hs.grad.year.7.county.match) %>%
  mutate(hs.grad.year.7.county.match = ifelse(hs.grad.year.7.county.match == "Location match", "Match", "No match")) 


```
The following analysis will determine which variables are most important in predicting whether an individual has meaningful employment in the same county as their high school the year they graduate.

Let's split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train grad year +7 county, echo=TRUE}
set.seed(1234)
sample_ind <- sample(nrow(master.grad.year.7.county.path), nrow(master.grad.year.7.county.path) *.7)

train <- master.grad.year.7.county.path[sample_ind,]

test <- master.grad.year.7.county.path[-sample_ind,]
```

<br>

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

<br>

```{r create decision tree grad year +7 county, echo=TRUE}
#Base model
grad.year.7.county.model <- rpart(hs.grad.year.7.county.match ~ ., data = train, method = "class", control = rpart.control(cp = 0))

```

```{r decision tree summary and plots grad year +7 county, echo=TRUE, include=FALSE}

#Summary
summary(grad.year.7.county.model)

#Plot tree
rpart.plot(grad.year.7.county.model)

```

```{r decision tree error grad year +7 county, echo=TRUE}

# Examine the complexity plot
printcp(grad.year.7.county.model)
plotcp(grad.year.7.county.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable important and it shows that the average wages as percent of state average, the post-secondary institution sector from which an individual graduated, the MCA scores, EDR, cte.achievement, ap exam and ACT exam, and the Demographer's RUCA category play an important role in this model.

<br>

```{r base model variable importance grad year +7 county, echo=TRUE}
grad.year.7.county.model$variable.importance
```

<br>

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy grad year +7 county, echo=TRUE}
test$pred <- predict(grad.year.7.county.model, test, type = "class")

base_accuracy <- mean(test$pred == test$hs.grad.year.7.county.match)

base_accuracy
```

<br>

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket.

<br>

```{r pre pruning  grad year +7 county, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
grad.year.7.county.model.preprune <- rpart(hs.grad.year.7.county.match ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 6, minsplit = 40))

#Summary
summary(grad.year.7.county.model.preprune)

#Plot tree
rpart.plot(grad.year.7.county.model.preprune)

# Examine the complexity plot
printcp(grad.year.7.county.model.preprune)
plotcp(grad.year.7.county.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(grad.year.7.county.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$hs.grad.year.7.county.match)

accuracy_preprun
```

<br>

The pre-pruning resulted in a significantly less complex tree with a .7997583 accuracy. Let's see what variables are important in this model.

Variable importance doesn't change much from the initial model. Post-secondary pathway, cte achievement, average wages and ap.exam are still the top. The MCA scores drop as well as the ACT exams.

<br>

```{r pre pruning variable importance grad year +7 county, echo=TRUE}
grad.year.7.county.model.preprune$variable.importance

```

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code:

<br>

```{r postpruning grad year +7 county, echo=TRUE}

# Prune the hr_base_model based on the optimal cp value
grad.year.7.county.model.postprune <- prune(grad.year.7.county.model, cp = .00069204 )

#Summary
summary(grad.year.7.county.model.postprune)

#Plot tree
rpart.plot(grad.year.7.county.model.postprune)

# Examine the complexity plot
printcp(grad.year.7.county.model.postprune)
plotcp(grad.year.7.county.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(grad.year.7.county.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$hs.grad.year.7.county.match)

accuracy_postprun

```

<br>

We still end up with a highly complex tree that is difficult to interpret. Let's check to see what variables are considered important.

It shows a bit of difference. The post-secondary pathway is still the top followed by average wages, however EDR jumps up above AP exam.

<br>

```{r post pruning variable importance grad year +7 county, echo=TRUE}
grad.year.7.county.model.postprune$variable.importance

```
<br>

Now let's compare the accuracy.

```{r compare accuracy grad year +7 county, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```
