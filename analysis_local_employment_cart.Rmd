---
title: "Analysis - local employment CART"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
runtime: shiny
resource_files:
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.cpg
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.dbf
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.prj
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.sbn
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.sbx
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.shp.xml
- Data/Shapefiles/County shapefiles/MNCounties_MNDOT.shx
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(sf)
library(ggrepel)
library(scales)
library(shiny)
library(shinycssloaders)
library(ggiraph)
library(kableExtra)
library(rmapshaper)
library(cowplot)
library(DT)
library(htmlwidgets)
library(RColorBrewer)
library(readxl)
library(janitor)
library(lubridate)
library(systemfonts)
reset_font_cache()
library(ggtext)
library(gmodels)
library(fastDummies)
library(car)
library(glmnet)
library(glmnetUtils)
library(pscl)
library(sjPlot)
library(rpart)
library(rpart.plot)
```

```{r join docs, include=FALSE}
theme_bar <- theme_bw() +
  theme(panel.grid.major = element_line(color = "grey70", size = 0.1),
        panel.grid.minor = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(face = "bold"),
        panel.border = element_blank(),
        legend.background = element_rect(fill = "transparent", color = "transparent"),
        legend.key = element_rect(fill = "transparent"),
        legend.key.size = unit(1, "lines"),
        legend.margin = margin(0,0,0,0),
        legend.title = element_blank(),
        legend.text = element_text(margin = margin(l = 2)),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))

theme_line <- theme_bw() +
  theme(legend.background = element_rect(fill = "transparent", color = "transparent"),
        legend.key = element_rect(fill = "transparent"),
        legend.text = element_text(margin = margin(l = 2)),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_line(color = "grey70", size = 0.1),
        axis.ticks = element_blank(),
        axis.text = element_text(face = "bold"),
        panel.border = element_blank(),
        legend.margin = margin(0,0,0,0),
        legend.key.size = unit(1, "lines"),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))


theme_sf <- theme_bw() +
  theme(axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks=element_blank(),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = "white"),
        panel.border = element_blank(),
        legend.title = element_blank(),
        legend.text = element_text(margin = margin(l = 2)),
        legend.margin = margin(0,0,0,0),
        legend.key.size = unit(1, "lines"),
        text = element_text(family = "Arial") ,
        plot.title.position = "plot",
        plot.title = element_text(face = "bold"))

regions <- read_csv("Data/Join docs/county_regions.csv") %>%
    select(5,6) %>%
    unique() %>%
    mutate(edr = str_replace(edr, "  ", " "),
           planning.region = str_replace(planning.region, " Minnesota", ""),
           planning.region = fct_relevel(planning.region, "Northwest", "Northeast", "Central", "Seven County Mpls-St Paul", "Southwest", "Southeast"),
           edr = fct_relevel(edr, "EDR 1 - Northwest", "EDR 2 - Headwaters", "EDR 3 - Arrowhead", "EDR 4 - West Central", "EDR 5 - North Central", "EDR 6E- Southwest Central", "EDR 6W- Upper Minnesota Valley", "EDR 7E- East Central", "EDR 7W- Central", "EDR 8 - Southwest", "EDR 9 - South Central", "EDR 10 - Southeast", "EDR 11 - 7 County Twin Cities", "Minnesota"))

counties.regions <- read_csv("Data/Join docs/county_regions.csv") %>%
  rename(mif = `MIF Region`) %>%
  mutate(countyfp = formatC(countyfp, width = 3, flag = "0"),
         Name = str_to_title(Name),
         Name = str_replace(Name, "Q", "q"),
         Name = str_replace(Name, "Of The", "of the"),
         Name = str_replace(Name, "Mcleod", "McLeod"),
         Dem_Desc = ifelse(Name == "Minnesota", "Minnesota", Dem_Desc) ,
         edr = str_replace(edr, "  ", " "),
         planning.region = str_replace(planning.region, " Minnesota", ""),
         planning.region = fct_relevel(planning.region, "Northwest", "Northeast", "Central", "Seven County Mpls-St Paul", "Southwest", "Southeast"),
         edr = fct_relevel(edr, "EDR 1 - Northwest", "EDR 2 - Headwaters", "EDR 3 - Arrowhead", "EDR 4 - West Central", "EDR 5 - North Central", "EDR 6E- Southwest Central", "EDR 6W- Upper Minnesota Valley", "EDR 7E- East Central", "EDR 7W- Central", "EDR 8 - Southwest", "EDR 9 - South Central", "EDR 10 - Southeast", "EDR 11 - 7 County Twin Cities", "Minnesota"),
         mif = ifelse(is.na(mif), "TC", mif),
         mif = as.factor(mif),
         mif = fct_relevel(mif, "NW", "NE", "WC", "EC", "SW", "SE", "TC"))


color.ruca <- c("Entirely rural" = "#009933", "Town/rural mix" = "#99CC33", "Urban/town/rural mix" = "#CC9966", "Entirely urban" = "#754C29", "Minnesota" = "black")

color.pr <- c("Northwest" = 	"#4575b4", "Northeast" = "grey", "Central" = "#fee090", "Seven County Mpls-St Paul" = "#d73027", "Southwest" = "#91bfdb", "Southeast" = "#fc8d59", "Minnesota" = "black")

color.edr <- c("EDR 1 - Northwest" = "#b3cde3", "EDR 2 - Headwaters" = "#8c96c6", "EDR 3 - Arrowhead" = "#fe9929", "EDR 4 - West Central" = "#8856a7", "EDR 5 - North Central" = "#810f7c", "EDR 6E- Southwest Central" = "#e5f5f9", "EDR 6W- Upper Minnesota Valley" = "#bdc9e1", "EDR 7E- East Central" = "#99d8c9", "EDR 7W- Central" = "#2ca25f", "EDR 8 - Southwest" = "#74a9cf", "EDR 9 - South Central" = "#0570b0", "EDR 10 - Southeast" = "#d7301f", "EDR 11 - 7 County Twin Cities" = "#d8b365", "Minnesota" = "black")

color.pr.edr <- c ("Northwest" = "#4575b4","Northeast" = "#e0f3f8", "Central" = "#fee090", "Seven County Mpls-St Paul" = "#d73027", "Southwest" = "#91bfdb", "Southeast" = "#fc8d59", "Minnesota" = "black", "EDR 1 - Northwest" = "#b3cde3", "EDR 2 - Headwaters" = "#8c96c6", "EDR 3 - Arrowhead" = "#fe9929", "EDR 4 - West Central" = "#8856a7", "EDR 5 - North Central" = "#810f7c", "EDR 6E- Southwest Central" = "#e5f5f9", "EDR 6W- Upper Minnesota Valley" = "#bdc9e1", "EDR 7E- East Central" = "#99d8c9", "EDR 7W- Central" = "#2ca25f", "EDR 8 - Southwest" = "#74a9cf", "EDR 9 - South Central" = "#0570b0", "EDR 10 - Southeast" = "#d7301f", "EDR 11 - 7 County Twin Cities" = "#d8b365")

mn_counties <- st_read("Data/Shapefiles/county shapefiles/MNCounties_MNDOT.shp", quiet = TRUE) %>%
  ms_simplify(keep = .01, keep_shapes = TRUE) %>%
  rename(countyfp = FIPS_CODE)


```

```{r master dataset}
master.original <- read_csv("Data/SLEDS/Masters/Master-updated-1.csv")

master.qual.names <- read_csv("Data/SLEDS/Masters/Master-final-after-mca.csv") 

master.states <- read_csv("Data/SLEDS/Masters/Master-states.csv")

```

```{r joining masters}

updated.qual.var.names <-  master.qual.names %>%
  select(-PersonID) %>%
  names()

quan.var.names <- c("total.cte.courses.taken", "avg.cte.intensity", "MCA.M", "MCA.R", "MCA.S", "avg.unemp.rate", "avg.wages.pct.state")

updated.independent.var.names <- c(updated.qual.var.names, quan.var.names)

cte.cc.var.names <- c("cte.1", "cte.2", "cte.3", "cte.4", "cte.5", "cte.6", "cte.7", "cte.8", "cte.9", "cte.10", "cte.11", "cte.12", "cte.14", "cte.21", "cte.22", "cte.23", "cte.24", "cte.25")

dep.var.names <- master.states %>%
  select(PersonID, grad.year.1, grad.year.5, grad.year.10)

master <- master.original %>%
  select(PersonID, all_of(`updated.independent.var.names`)) %>%
  left_join(dep.var.names, by = "PersonID") %>%
  mutate_at(2:12, as.factor) %>%
  mutate_at(20:22, as.factor) %>%
  mutate(ps.grad.InstitutionSector = ifelse(ps.grad.InstitutionSector %in% c("5", "6", "7", "8", "9"), "11", as.character(ps.grad.InstitutionSector)),
         ps.grad.InstitutionSector = as.factor(ps.grad.InstitutionSector),
         grad.year.1 = fct_relevel(grad.year.1, "Meaningful emp County", "Meaningful emp EDR", "Meaningful emp SW", "Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps"),
         grad.year.5 = fct_relevel(grad.year.5, "Meaningful emp County", "Meaningful emp EDR", "Meaningful emp SW", "Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps"),
         grad.year.10 = fct_relevel(grad.year.10, "Meaningful emp County", "Meaningful emp EDR", "Meaningful emp SW", "Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps")) %>%
  droplevels()
```


<br>

We will use a tree-based method for classification - CART analysis. This type of analysis involves stratifying and/or segmenting the predictor space into a number of simple regions. Essentially, it's another way to see which independent variables play a role in if an individual has meaningful employment in the local region X. We will be using the independent variables that were identified as being important in the multiple correspondence analysis.

There are a number of states at which we categorize individuals in the dataset;

1. Has meaningful employment in the same county as their high school.
2. Has meaningful employment in the same EDR as their high school, but not county.
3. Has meaningful employment in Southwest Minnesota, but not in the same EDR as their high school.
4. Has meaningful employment in Minnesota, but not in Southwest Minnesota.
5. Is attending post-secondary.
6. Has a MN employment record but it's not meaningful, and not attending post-secondary.
7. Does not have a MN employment record and is not attending post-secondary.

There are three "times" in which we checked to see if the individual had meaningful employment within these geographies;

1. one year after graduating high school
2. five years after graduation, and
3. ten years after graduation. 

Meaningful employment is determined by whether an individual worked 1,000 hours for an employer during time X. In addition, if the individual is working for an employer but not meaningful at time X but worked 1,000 hours for that employer during another year it's still considered "meaningful". 

Due to time x potentially being passed the date of the latest data (2019) for some individuals, the analysis below will filter out all individuals where time x is after 2019. 

The primary independent variables that the cross tables indicated as important are;

```{r list of ind var}
ind.var <-master %>%
  select(-PersonID, -grad.year.1, -grad.year.5, -grad.year.10)
  
ind.var.names <- ind.var %>%
  names()

ind.var %>%
  lapply(class)
```

In addition to eliminating those variables, we will also simplify the ps.grad.InstitutionSector to the following codes;

* 1 = graduated from the following insitutions
    + Public, 4-year (1)
    + Private, not for profit 4-year (2)
    + Private, for profit 4-year (3)
* 2 = graduated from the following institutions
    + Private, not for profit 2-year (5, 11)
    + Private, for profit 2-year (6, 11)
    + Public, less than 2-year (7, 11)
    + Private, not for profit less than 2-year (8, 11)
    + Private for-profit, less-than 2-year (9, 11)
* 3 = graduated from multiple institution sectors (10)
* 4 = graduated from a public, 2-year institution (4,4)
* 5 = Did not graduate or attend a post-secondary institution


```{r updating master}
updated.master <- master %>%
  mutate(ps.grad.InstitutionSector = ifelse(ps.grad.InstitutionSector %in% c(1,2,3), 1,
                                            ifelse(ps.grad.InstitutionSector == 11, 2,
                                                   ifelse(ps.grad.InstitutionSector == 10, 3,
                                                          ifelse(ps.grad.InstitutionSector == 4, 4, 5)))))

names(updated.master)

```



<br>

# Methodology

We are going to use CART/Decision Trees to see which independent variables are important. One limitation of this method is that the dependent variable must be binary. So, we will need to force our 7 states into 2 states. We will begin by doing the following;

1. Meaningful emp in SW: this will include the following categories for each time.x;
  * Meaningful emp County
  * Meaningful emp EDR
  * Meaningful emp SW
2. No meaningful emp in SW: this will include the following categories for each time.x:
  * Meaningful emp MN
  * Attending ps
  * Not meaningful, not attending ps
  * No MN emp record, not attending ps
  
Once we look at this analysis, we can determine if we want to split the binary differently for further analysis.

# Meaningful emp in SW

First, let's re-categorize the dependent variables so that they are binary.

<br>

```{r prep meaningful emp in sw, echo=TRUE}
meaningful.emp.sw <- updated.master %>%
  mutate(grad.year.1 = ifelse(grad.year.1 %in% c("Meaningful emp County", "Meaningful emp EDR", "Meaningful emp SW"), "Meaningful emp SW", 
                              ifelse(grad.year.1 %in% c("Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps"), "No meaningful emp SW",
                                     ifelse(grad.year.1 == "After 2019", "After 2019", as.character(grad.year.1)))),
         grad.year.5 = as.factor(grad.year.1),
         grad.year.5 = ifelse(grad.year.5 %in% c("Meaningful emp County", "Meaningful emp EDR", "Meaningful emp SW"), "Meaningful emp SW", 
                              ifelse(grad.year.5 %in% c("Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps"), "No meaningful emp SW",
                                     ifelse(grad.year.5 == "After 2019", "After 2019", as.character(grad.year.5)))),
         grad.year.5 = as.factor(grad.year.5),
         grad.year.10 = ifelse(grad.year.10 %in% c("Meaningful emp County", "Meaningful emp EDR", "Meaningful emp SW"), "Meaningful emp SW", 
                              ifelse(grad.year.10 %in% c("Meaningful emp MN", "Attending ps", "Not meaningful, not attending ps", "No MN emp record, not attending ps"), "No meaningful emp SW",
                                     ifelse(grad.year.10 == "After 2019", "After 2019", as.character(grad.year.10)))),
         grad.year.10 = as.factor(grad.year.10),
         grad.year.1 = fct_relevel(grad.year.1, "Meaningful emp SW", "No meaningful emp SW", "After 2019"),
         grad.year.5 = fct_relevel(grad.year.5, "Meaningful emp SW", "No meaningful emp SW", "After 2019"),
         grad.year.10 = fct_relevel(grad.year.10, "Meaningful emp SW", "No meaningful emp SW", "After 2019"))

```

<br>

## One year after graduation

Since our dependent variable includes a state in which someone is attending post-secondary and the post-secondary variables are related to an individual finishing post-secondary, we will remove "ps.grad.InstitutionSector" and the "highest.cred.level" variable from the analysis.

```{r prep meaningful emp SW grad year 1}
meaningful.emp.sw.grad.year.1 <- meaningful.emp.sw %>%
  filter(grad.year.1 != "After 2019") %>%
  select(-PersonID, -grad.year.5, -grad.year.10, -ps.grad.InstitutionSector, -highest.cred.level)

names(meaningful.emp.sw.grad.year.1)
```
### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp SW grad year 1, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.sw.grad.year.1), nrow(meaningful.emp.sw.grad.year.1) *.7)

train <- meaningful.emp.sw.grad.year.1[sample_ind,]

test <- meaningful.emp.sw.grad.year.1[-sample_ind,]
```

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

<br>

```{r create decision tree meaningful emp SW grad year 1, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.sw.grad.year.1.model <- rpart(grad.year.1 ~ ., data = train, method = "class", control = rpart.control(cp = 0))

#Summary
summary(meaningful.emp.sw.grad.year.1.model)

```

```{r decision tree plot meaningful emp SW grad year 1}
#Plot tree
rpart.plot(meaningful.emp.sw.grad.year.1.model)

# Examine the complexity plot
printcp(meaningful.emp.sw.grad.year.1.model)

plotcp(meaningful.emp.sw.grad.year.1.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable important and it shows that average wages, average CTE intensity, the average unemployment rate, and total CTE courses taken play a pretty big role.

<br>

```{r base model variable importance meaningful emp SW grad year 1, echo=TRUE}

meaningful.emp.sw.grad.year.1.model$variable.importance

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp SW grad year 1, echo=TRUE}
test$pred <- predict(meaningful.emp.sw.grad.year.1.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.1)

base_accuracy
```

### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket.

<br>

```{r pre pruning  meaningful emp SW grad year 1, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
meaningful.emp.sw.grad.year.1.model.preprune <- rpart(grad.year.1 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 5, minsplit = 10))

```

```{r pre pruning summary meaningful emp SW grad year 1, include=FALSE}

#Summary
summary(meaningful.emp.sw.grad.year.1.model.preprune)
```

```{r pre pruning plot meaningful emp SW grad year 1, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.sw.grad.year.1.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.sw.grad.year.1.model.preprune)
plotcp(meaningful.emp.sw.grad.year.1.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.sw.grad.year.1.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.1)

accuracy_preprun
```

The pre-pruning resulted in a significantly less complex tree with a .877442 accuracy. Let's see what variables are important in this model.

This model does indicate a difference in importance when pruned. Average wages are no longer as important, instead taking the ACT, MCA - reading scores, are important. The total number of cte courses increases as well while avg.cte.intensity is significantly lower. 

<br>

```{r pre pruning variable importance meaningful emp SW grad year 1, echo=TRUE}
meaningful.emp.sw.grad.year.1.model.preprune$variable.importance
```
### Post-pruning

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code:

<br>

```{r postpruning meaningful emp SW grad year 1, echo=TRUE}

# Prune the hr_base_model based on the optimal cp value
meaningful.emp.sw.grad.year.1.model.postprune <- prune(meaningful.emp.sw.grad.year.1.model, cp = .00052929)

#Summary
summary(meaningful.emp.sw.grad.year.1.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.sw.grad.year.1.model.postprune)

# Examine the complexity plot
printcp(meaningful.emp.sw.grad.year.1.model.postprune)
plotcp(meaningful.emp.sw.grad.year.1.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.sw.grad.year.1.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.1)

accuracy_postprun

```

<br>

We still end up with a highly complex tree that is difficult to interpret. Let's check to see what variables are considered important.

And it tells me that none of the variables are important?????

<br>

```{r post pruning variable importance meaningful emp SW grad year 1, echo=TRUE}
meaningful.emp.sw.grad.year.1.model.postprune$variable.importance

```
<br>

Now let's compare the accuracy.

```{r compare accuracy meaningful emp SW grad year 1, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```
### Summary

The variable importance across the models do vary quite a bit. The most consistent variables that were high in the importance values were;

* took the ACT
* CTE coursework
* special education status
* MCA - reading score
* average wages as a percent of the state average.


<br>

## Five years after graduation

Next we will look at the variables importance at five years after graduation. At this point we will bring back the post-secondary variables.

```{r prep meaningful emp SW grad year 5}
meaningful.emp.sw.grad.year.5 <- meaningful.emp.sw %>%
  filter(grad.year.5 != "After 2019") %>%
  select(-PersonID, -grad.year.1, -grad.year.10)

names(meaningful.emp.sw.grad.year.5)
```

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp SW grad year 5, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.sw.grad.year.5), nrow(meaningful.emp.sw.grad.year.5) *.7)

train <- meaningful.emp.sw.grad.year.5[sample_ind,]

test <- meaningful.emp.sw.grad.year.5[-sample_ind,]
```

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

<br>

```{r create decision tree meaningful emp SW grad year 5, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.sw.grad.year.5.model <- rpart(grad.year.5 ~ ., data = train, method = "class", cp = 0)

#Summary
summary(meaningful.emp.sw.grad.year.5.model)

```

```{r decision tree plot meaningful emp SW grad year 5}
#Plot tree
rpart.plot(meaningful.emp.sw.grad.year.5.model)

# Examine the complexity plot
printcp(meaningful.emp.sw.grad.year.5.model)

plotcp(meaningful.emp.sw.grad.year.5.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable important and it shows that the variables related to post-secondary institutions, CTE courses, and the economics of their county are all pretty high.

<br>

```{r base model variable importance meaningful emp SW grad year 5, echo=TRUE}

meaningful.emp.sw.grad.year.5.model$variable.importance

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp SW grad year 5, echo=TRUE}
test$pred <- predict(meaningful.emp.sw.grad.year.5.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.5)

base_accuracy
```


### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket.

<br>

```{r pre pruning  meaningful emp SW grad year 5, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
meaningful.emp.sw.grad.year.5.model.preprune <- rpart(grad.year.5 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 10, minsplit = 40))

```

```{r pre pruning summary meaningful emp sw grad year 5, include=FALSE}

#Summary
summary(meaningful.emp.sw.grad.year.5.model.preprune)
```

```{r pre pruning plot meaningful emp SW grad year 5, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.sw.grad.year.5.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.sw.grad.year.5.model.preprune)
plotcp(meaningful.emp.sw.grad.year.5.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.sw.grad.year.5.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.5)

accuracy_preprun
```

The pre-pruning resulted in a significantly less complex tree with a .88 accuracy. Let's see what variables are important in this model.

This model does indicate a difference in importance when pruned. The post-secondary stuff is still extremely important, but the prep work in school take the place of county economics and CTE courses. 

<br>

```{r pre pruning variable importance meaningful emp SW grad year 5, echo=TRUE}
meaningful.emp.sw.grad.year.5.model.preprune$variable.importance
```

### Post-pruning 

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code:

<br>

```{r postpruning meaningful emp SW grad year 5, echo=TRUE}

# Prune the hr_base_model based on the optimal cp value
meaningful.emp.sw.grad.year.5.model.postprune <- prune(meaningful.emp.sw.grad.year.5.model, cp = .00030875)

#Summary
summary(meaningful.emp.sw.grad.year.5.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.sw.grad.year.5.model.postprune)

# Examine the complexity plot
printcp(meaningful.emp.sw.grad.year.5.model.postprune)
plotcp(meaningful.emp.sw.grad.year.5.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.sw.grad.year.5.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.5)

accuracy_postprun

```

<br>

We still end up with a highly complex tree that is difficult to interpret. Let's check to see what variables are considered important.

And it tells me that the post-secondary variables are still very important. Interestingly, the county economics and CTE coursework rises to the top. It seems that those variables are much more important when the decision tree is more complex. In order to simplify the decision trees, those kind of get put by the way side. I'm assuming that the branching gets more nuanced so that the greater then/lesser than split occurs in many areas through those variables.

<br>

```{r post pruning variable importance grad year +0 county, echo=TRUE}
meaningful.emp.sw.grad.year.5.model.postprune$variable.importance

```
<br>

Now let's compare the accuracy.

```{r compare accuracy grad year +0 county, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```
### Summary

Overall, the variables that were the most consistently important throughout the analysis were the post-secondary variables. Both the institution sector and highest credential earned were in the top five for all three models. 

In addition, the CTE coursework (average CTE intensity, number of CTE courses taken) as well as the high school county economics (unemployment and wages) showed up as important in the more complexy model (base and post-pruning) but not in the simpler decision tree with less branching. In the pre-pruned tree, the testing and prepping in school were more important.

<br>

## Ten years after graduation

Next we will look at the variables importance at five years after graduation. At this point we will bring back the post-secondary variables.

```{r prep meaningful emp SW grad year 10}
meaningful.emp.sw.grad.year.10 <- meaningful.emp.sw %>%
  filter(grad.year.10 != "After 2019") %>%
  select(-PersonID, -grad.year.1, -grad.year.5)

names(meaningful.emp.sw.grad.year.10)
```

### Base model

First we will split the data into two sets, Train and Test, in a 70:30 ratio. The Train set is used for training and creating the model. The Test set is considered to be a dummy production environment to test predictions and evaluate the accuracy of the model.

<br>

```{r split dataset into test and train meaningful emp SW grad year 10, echo=TRUE}
set.seed(1234)

sample_ind <- sample(nrow(meaningful.emp.sw.grad.year.10), nrow(meaningful.emp.sw.grad.year.10) *.7)

train <- meaningful.emp.sw.grad.year.10[sample_ind,]

test <- meaningful.emp.sw.grad.year.10[-sample_ind,]
```

Next, we create a decision tree model by calling the rpart function. Let's first create a base model with default parameters and value. The CP (complexity parameter) is used to control tree growth. If the cost of adding a variable is higher then the value of CP, then tree growth stops.

<br>

```{r create decision tree meaningful emp SW grad year 10, echo=TRUE, include = FALSE}
#Base model

meaningful.emp.sw.grad.year.10.model <- rpart(grad.year.10 ~ ., data = train, method = "class", cp = 0)

#Summary
summary(meaningful.emp.sw.grad.year.10.model)

```

```{r decision tree plot meaningful emp SW grad year 10}
#Plot tree
rpart.plot(meaningful.emp.sw.grad.year.10.model)

# Examine the complexity plot
printcp(meaningful.emp.sw.grad.year.10.model)

plotcp(meaningful.emp.sw.grad.year.10.model)

```

<br>

The resulting model produced a VERY complex tree with too many nodes that it isn't interpretable. However, examining the complexity parameters shows that I have an increasing cross-validated error which provides evidence of a decision tree with too much complexity.

Below are the values in variable important and it shows that the variables related to CTE courses, high school county economics, and the post-secondary institutions are all pretty high.

<br>

```{r base model variable importance meaningful emp SW grad year 10, echo=TRUE}

meaningful.emp.sw.grad.year.10.model$variable.importance

```

Next, the accuracy of the model is computed and stored in a variable base_accuracy so we can compare it to our pruned trees later.

<br>

```{r model accuracy meaningful emp SW grad year 10, echo=TRUE}
test$pred <- predict(meaningful.emp.sw.grad.year.10.model, test, type = "class")

base_accuracy <- mean(test$pred == test$grad.year.10)

base_accuracy
```


### Pre-pruning

Next, we need to prune. We can either pre-prune or post-prune. We will start with pre-pruning and use each method - max depth, min depth, and min bucket.

<br>

```{r pre pruning  meaningful emp SW grad year 10, echo=TRUE}
# Grow a tree with minsplit of 40 and max depth of 10
meaningful.emp.sw.grad.year.10.model.preprune <- rpart(grad.year.10 ~ ., data = train, method = "class", 
                   control = rpart.control(cp = 0, maxdepth = 7, minsplit = 40))

```

```{r pre pruning summary meaningful emp sw grad year 10, include=FALSE}

#Summary
summary(meaningful.emp.sw.grad.year.10.model.preprune)
```

```{r pre pruning plot meaningful emp SW grad year 10, echo=TRUE}
#Plot tree
rpart.plot(meaningful.emp.sw.grad.year.10.model.preprune)

# Examine the complexity plot
printcp(meaningful.emp.sw.grad.year.10.model.preprune)
plotcp(meaningful.emp.sw.grad.year.10.model.preprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.sw.grad.year.10.model.preprune, test, type = "class")

accuracy_preprun <- mean(test$pred == test$grad.year.10)

accuracy_preprun
```

The pre-pruning resulted in a significantly less complex tree with a .75 accuracy. Let's see what variables are important in this model.

This model does indicate a difference in importance when pruned. The MCA testing, CTE coursework are important in this model, as well as the average wages.

<br>

```{r pre pruning variable importance meaningful emp SW grad year 10, echo=TRUE}
meaningful.emp.sw.grad.year.10.model.preprune$variable.importance
```

### Post-pruning 

Next, let's try postpruning. The idea here is to allow the decision tree to grow fully and observe the CP value. Next, we prune/cut the tree with the optimal CP value as the parameter as shown in below code:

<br>

```{r postpruning meaningful emp SW grad year 10, echo=TRUE}

# Prune the hr_base_model based on the optimal cp value
meaningful.emp.sw.grad.year.10.model.postprune <- prune(meaningful.emp.sw.grad.year.10.model, cp = 0.00134844)

#Summary
summary(meaningful.emp.sw.grad.year.10.model.postprune)

#Plot tree
rpart.plot(meaningful.emp.sw.grad.year.10.model.postprune)

# Examine the complexity plot
printcp(meaningful.emp.sw.grad.year.10.model.postprune)
plotcp(meaningful.emp.sw.grad.year.10.model.postprune)


# Compute the accuracy of the pruned tree

test$pred <- predict(meaningful.emp.sw.grad.year.10.model.postprune, test, type = "class")

accuracy_postprun <- mean(test$pred == test$grad.year.10)

accuracy_postprun

```

<br>

We still end up with a highly complex tree that is difficult to interpret. Let's check to see what variables are considered important.

This model tells me that the MCA reading test, the CTE coursework, the highest credential earned and the average wages play an important role.

<br>

```{r post pruning variable importance meaningful emp SW grad year 10, echo=TRUE}
meaningful.emp.sw.grad.year.10.model.postprune$variable.importance

```
<br>

Now let's compare the accuracy.

```{r compare accuracy meaningful emp SW grad year 10, echo=TRUE}
data.frame(base_accuracy, accuracy_preprun, accuracy_postprun)

```

### Summary

Overall, the variables that were the most consistently important throughout the analysis were the following;

* The average CTE intensity
* MCA - reading
* Average wages as a percent of state average
* Total CTE courses taken
* Highest credentials earned.

<br>

## Summary across time

* 1 year after graduation
  + Took the ACT
  + CTE coursework
  + Special education status
  + MCA - reading score
  + Average wages as a percent of state average
* 5 years after graduation
  + Post-secondary institution
  + Highest credentials earned
  + CTE coursework
  + High school county economics
* 10 years after graduation
  + CTE coursework
  + MCA - reading score
  + Average wages as a percent of state average
  + Highest credentials earned
  

